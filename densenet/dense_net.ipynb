{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense net Impl\n",
    "\n",
    "There are certain parts of the code which call the device: \"cpu\", if you end up using the ecetesla servers, this line will update the device accordingly (i.e. we dont have to worry about it)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from image_dataset import MultiLabelImageDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "# File Paths\n",
    "DATASET_PATH = \"../dataset.pt\"\n",
    "MODEL_SAVE_PATH = \"densenet_model.pth\"\n",
    "CSV_LOG_PATH = \"densenet_training_log.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using densenet121 adapted for multi-label classification\n",
    "\n",
    "Use default function params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_densenet(num_classes=290, pretrained=True):\n",
    "    model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT if pretrained else None)\n",
    "\n",
    "    in_features = model.classifier.in_features\n",
    "    \n",
    "    # replace with a linear layer for 290 classes\n",
    "    model.classifier = nn.Linear(in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision_at_20(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    all_ap = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            topk_indices = torch.argsort(probs, dim=1, descending=True)[:, :20]\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                true_labels = labels[i].nonzero(as_tuple=True)[0]\n",
    "                if len(true_labels) == 0:\n",
    "                    continue\n",
    "\n",
    "                precision_sum = 0.0\n",
    "                hits = 0\n",
    "                for k, idx in enumerate(topk_indices[i]):\n",
    "                    if idx in true_labels:\n",
    "                        hits += 1\n",
    "                        precision_at_k = hits / (k + 1)\n",
    "                        precision_sum += precision_at_k\n",
    "\n",
    "                ap = precision_sum / min(len(true_labels), 20)\n",
    "                all_ap.append(ap)\n",
    "\n",
    "    return float(np.mean(all_ap)) if len(all_ap) > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Eval\n",
    "\n",
    "** Can comment the line to evaluate map@20 on train if we want to save time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    lr=1e-3,\n",
    "    num_epochs=3,\n",
    "    model_save_path=MODEL_SAVE_PATH,\n",
    "    csv_log_path=CSV_LOG_PATH,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train DenseNet for multi-label classification and evaluate with MAP@20.\n",
    "    Saves the model and logs to CSV, also plots progress.\n",
    "    \"\"\"\n",
    "    # Send model to GPU if available\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # For plotting/logging\n",
    "    epoch_list = []\n",
    "    train_loss_list = []\n",
    "    train_map_list = []\n",
    "    test_map_list = []\n",
    "    \n",
    "    # CSV columns\n",
    "    columns = [\"epoch\", \"train_loss\", \"train_map20\", \"test_map20\"]\n",
    "    if not os.path.exists(csv_log_path):\n",
    "        pd.DataFrame(columns=columns).to_csv(csv_log_path, index=False)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluate MAP@20 on train set (optional, can be time-consuming)\n",
    "        train_map20 = mean_average_precision_at_20(model, train_loader, device=device)\n",
    "        \n",
    "        # Evaluate MAP@20 on test set\n",
    "        test_map20 = mean_average_precision_at_20(model, test_loader, device=device)\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{num_epochs}, \"\n",
    "              f\"Train Loss: {avg_loss:.4f}, \"\n",
    "              f\"Train MAP@20: {train_map20:.4f}, \"\n",
    "              f\"Test MAP@20: {test_map20:.4f}\")\n",
    "        \n",
    "        epoch_list.append(epoch)\n",
    "        train_loss_list.append(avg_loss)\n",
    "        train_map_list.append(train_map20)\n",
    "        test_map_list.append(test_map20)\n",
    "        \n",
    "        # Append to CSV\n",
    "        df_log = pd.DataFrame([[epoch, avg_loss, train_map20, test_map20]], columns=columns)\n",
    "        df_log.to_csv(csv_log_path, mode='a', header=False, index=False)\n",
    "    \n",
    "    # Save the model weights\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "    \n",
    "    # Plot training loss & test MAP@20\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    # Plot training loss\n",
    "    color1 = \"tab:blue\"\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Train Loss\", color=color1)\n",
    "    ax1.plot(epoch_list, train_loss_list, color=color1, marker=\"o\", label=\"Train Loss\")\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color1)\n",
    "\n",
    "    # Plot test MAP@20\n",
    "    ax2 = ax1.twinx()\n",
    "    color2 = \"tab:red\"\n",
    "    ax2.set_ylabel(\"MAP@20\", color=color2)\n",
    "    ax2.plot(epoch_list, test_map_list, color=color2, marker=\"x\", label=\"Test MAP@20\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=color2)\n",
    "\n",
    "    plt.title(\"Train Loss vs Test MAP@20 (DenseNet)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Code\n",
    "1. Load Dataset\n",
    "2. Train/Test split\n",
    "3. Create Dataloaders\n",
    "4. Create Densenet model\n",
    "5. Train & Eval\n",
    "6. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 5950\n",
      "Train set: 4760, Test set: 1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /Users/rianarang/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:11<00:00, 2.75MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet model created.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train/14ffd1d1-4a94-42ea-858f-3afc1b313bbe.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 30\u001b[0m\n\u001b[1;32m     18\u001b[0m     train_and_evaluate(\n\u001b[1;32m     19\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     20\u001b[0m         train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     29\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m create_densenet(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m290\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDenseNet model created.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_SAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCSV_LOG_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 36\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train_loader, test_loader, lr, num_epochs, model_save_path, csv_log_path, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     34\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     37\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     38\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fgvc_test/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fgvc_test/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fgvc_test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fgvc_test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fgvc_test/lib/python3.9/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Programming/MSE_546_Project/densenet/../image_dataset.py:51\u001b[0m, in \u001b[0;36mMultiLabelImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, img_name)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Load the image and convert to RGB\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Apply the transformations if defined\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fgvc_test/lib/python3.9/site-packages/PIL/Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3224\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3227\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3228\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train/14ffd1d1-4a94-42ea-858f-3afc1b313bbe.png'"
     ]
    }
   ],
   "source": [
    "def run_experiment(num_epochs=3, lr=1e-3, device=\"cpu\"):\n",
    "    dataset = torch.load(DATASET_PATH)\n",
    "    total_samples = len(dataset)\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    \n",
    "    train_size = int(0.8 * total_samples)\n",
    "    test_size = total_samples - train_size\n",
    "    torch.manual_seed(42)\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    print(f\"Train set: {len(train_dataset)}, Test set: {len(test_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    model = create_densenet(num_classes=290, pretrained=True)\n",
    "    print(\"DenseNet model created.\")\n",
    "    \n",
    "    train_and_evaluate(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        lr=lr,\n",
    "        num_epochs=num_epochs,\n",
    "        model_save_path=MODEL_SAVE_PATH,\n",
    "        csv_log_path=CSV_LOG_PATH,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "run_experiment(num_epochs=3, lr=1e-3, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgvc_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
